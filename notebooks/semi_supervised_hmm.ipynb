{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as onp\n",
    "import seaborn as sns; sns.set(palette=\"bright\")\n",
    "import tqdm\n",
    "\n",
    "import jax.numpy as np\n",
    "from jax import jit, random\n",
    "from jax.config import config; config.update(\"jax_platform_name\", \"cpu\")\n",
    "from jax.scipy.special import logit, logsumexp\n",
    "from jax.tree_util import tree_map, tree_multimap\n",
    "\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.handlers import sample\n",
    "from numpyro.hmc_util import initialize_model\n",
    "from numpyro.mcmc import hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = 3\n",
    "num_words = 10\n",
    "num_supervised_data = 1\n",
    "num_unsupervised_data = 5\n",
    "rng = random.PRNGKey(1)\n",
    "rng, rng_transition, rng_emission = random.split(rng, 3)\n",
    "\n",
    "transition_prior = np.ones(num_categories)\n",
    "emission_prior = np.full((num_words,), 0.1)\n",
    "\n",
    "transition_prob = dist.dirichlet.rvs(transition_prior, size=num_categories, random_state=rng_transition)\n",
    "emission_prob = dist.dirichlet.rvs(emission_prior, size=num_categories, random_state=rng_emission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equilibrium(mc_matrix):\n",
    "    n = mc_matrix.shape[0]\n",
    "    return np.sum(onp.linalg.inv(np.identity(n) - mc_matrix.T + 1), axis=-1)\n",
    "\n",
    "start_prob = equilibrium(transition_prob)\n",
    "\n",
    "# simulate data\n",
    "categories, words = [], []\n",
    "for t in range(num_supervised_data + num_unsupervised_data):\n",
    "    rng, rng_transition, rng_emission = random.split(rng, 3)\n",
    "    if t == 0 or t == num_supervised_data:\n",
    "        category = dist.categorical.rvs(start_prob, random_state=rng_transition)\n",
    "    else:\n",
    "        category = dist.categorical.rvs(transition_prob[category], random_state=rng_transition)\n",
    "    word = dist.categorical.rvs(emission_prob[category], random_state=rng_emission)\n",
    "    categories.append(category)\n",
    "    words.append(word)\n",
    "categories, words = np.stack(categories), np.stack(words)\n",
    "\n",
    "# split into supervised data and unsupervised data\n",
    "supervised_categories = categories[:num_supervised_data]\n",
    "supervised_words = categories[:num_supervised_data]\n",
    "unsupervised_words = categories[num_supervised_data:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_posterior(posterior):\n",
    "    # generate Marginal distribution for `transition_prob` from posterior\n",
    "    marginal = posterior.marginal([\"transition_prob\"])\n",
    "    # get support of the marginal distribution\n",
    "    trace_transition_prob = marginal.support()[\"transition_prob\"]  # shape: num_samples x 3 x 3\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(num_categories):\n",
    "        for j in range(num_categories):\n",
    "            sns.distplot(trace_transition_prob[:, i, j], hist=False, kde_kws={\"lw\": 2},\n",
    "                         label=\"transition_prob[{}, {}], true value = {:.2f}\"\n",
    "                         .format(i, j, transition_prob[i, j]))\n",
    "    plt.xlabel(\"Probability\", fontsize=13)\n",
    "    plt.ylabel(\"Frequency\", fontsize=13)\n",
    "    plt.title(\"Transition probability posterior\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_log_prob(prev_log_prob, curr_word, transition_log_prob, emission_log_prob):\n",
    "    log_prob = emission_log_prob[:, curr_word] + transition_log_prob\n",
    "    log_prob = log_prob + np.expand_dims(prev_log_prob, axis=1)\n",
    "    return logsumexp(log_prob, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_supervised_hmm(supervised_categories, supervised_words, unsupervised_words):\n",
    "    transition_prob = sample(\"transition_prob\", dist.dirichlet(\n",
    "        np.broadcast_to(transition_prior, (num_categories, num_categories))))\n",
    "    emission_prob = sample(\"emission_prob\", dist.dirichlet(\n",
    "        np.broadcast_to(emission_prior, (num_categories, num_words))))\n",
    "\n",
    "    category = supervised_categories[0]\n",
    "    for t in range(len(supervised_words)):\n",
    "        if t > 0:\n",
    "            category = sample(\"category_{}\".format(t), dist.categorical(transition_prob[category]),\n",
    "                              obs=supervised_categories[t])\n",
    "        sample(\"word_{}\".format(t), dist.categorical(emission_prob[category]),\n",
    "               obs=supervised_words[t])\n",
    "\n",
    "    transition_log_prob = np.log(transition_prob)\n",
    "    emission_log_prob = np.log(emission_prob)\n",
    "    log_prob = emission_log_prob[:, unsupervised_words[0]]\n",
    "    for t in range(1, len(unsupervised_words)):\n",
    "        log_prob = forward_log_prob(log_prob, unsupervised_words[t],\n",
    "                                    transition_log_prob, emission_log_prob)\n",
    "    prob = np.clip(np.exp(logsumexp(log_prob, axis=0)), a_min=np.finfo(log_prob.dtype).tiny)\n",
    "    return sample(\"forward_prob\", dist.bernoulli(prob), obs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc(sample_kernel, state, num_samples, transform):\n",
    "    for i in tqdm.tqdm(range(num_samples)):\n",
    "        state = sample_kernel(state)\n",
    "        state_out = transform(tree_map(lambda x: np.expand_dims(x, axis=0), state))\n",
    "        if i == 0:\n",
    "            states = state_out\n",
    "        else:\n",
    "            states = tree_multimap(lambda x, y: np.concatenate((x, y))\n",
    "                                   if x is not None else None, states, state_out)\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params, potential_fn, transform_fn = initialize_model(\n",
    "    random.PRNGKey(2), semi_supervised_hmm,\n",
    "    (supervised_categories, supervised_words, unsupervised_words), {})\n",
    "init_kernel, sample_kernel = hmc(potential_fn, algo=\"NUTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to compile sample_kernel: 10.987462282180786\n"
     ]
    }
   ],
   "source": [
    "hmc_state, _, _ = init_kernel(init_params, num_warmup_steps=0, adapt_step_size=False,\n",
    "                              run_warmup=False)\n",
    "\n",
    "jsample_kernel = jit(sample_kernel)\n",
    "start = time.time()\n",
    "hmc_state = hmc_state.update(step_size=100.)  # HACK: force fast compiling!\n",
    "jsample_kernel(hmc_state)\n",
    "hmc_state = hmc_state.update(step_size=1.)\n",
    "print(\"time to compile sample_kernel:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of leapfrog steps: 100\n",
      "avg. time for each step : 0.09226186275482177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "start = time.time()\n",
    "hmc_states = mcmc(jsample_kernel, hmc_state, num_samples,\n",
    "                  transform=lambda state: {\"transition_prob\": transform_fn(state.z)[\"transition_prob\"],\n",
    "                                           \"num_steps\": state.num_steps})\n",
    "num_leapfrogs = np.sum(hmc_states[\"num_steps\"]).copy()\n",
    "print(\"number of leapfrog steps:\", num_leapfrogs)\n",
    "print(\"avg. time for each step :\", (time.time() - start) / num_leapfrogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data {\n",
      "  int<lower=1> K;  // num categories\n",
      "  int<lower=1> V;  // num words\n",
      "  int<lower=0> T;  // num supervised items\n",
      "  int<lower=1> T_unsup;  // num unsupervised items\n",
      "  int<lower=1,upper=V> w[T]; // words\n",
      "  int<lower=1,upper=K> z[T]; // categories\n",
      "  int<lower=1,upper=V> u[T_unsup]; // unsup words\n",
      "  vector<lower=0>[K] alpha;  // transit prior\n",
      "  vector<lower=0>[V] beta;   // emit prior\n",
      "}\n",
      "parameters {\n",
      "  simplex[K] theta[K];  // transit probs\n",
      "  simplex[V] phi[K];    // emit probs\n",
      "}\n",
      "model {\n",
      "  for (k in 1:K) \n",
      "    theta[k] ~ dirichlet(alpha);\n",
      "  for (k in 1:K)\n",
      "    phi[k] ~ dirichlet(beta);\n",
      "  for (t in 1:T)\n",
      "    w[t] ~ categorical(phi[z[t]]);\n",
      "  for (t in 2:T)\n",
      "    z[t] ~ categorical(theta[z[t-1]]);\n",
      "\n",
      "  { \n",
      "    // forward algorithm computes log p(u|...)\n",
      "    real acc[K];\n",
      "    real gamma[T_unsup,K];\n",
      "    for (k in 1:K)\n",
      "      gamma[1,k] <- log(phi[k,u[1]]);\n",
      "    for (t in 2:T_unsup) {\n",
      "      for (k in 1:K) {\n",
      "        for (j in 1:K)\n",
      "          acc[j] <- gamma[t-1,j] + log(theta[j,k]) + log(phi[k,u[t]]);\n",
      "        gamma[t,k] <- log_sum_exp(acc);\n",
      "      }\n",
      "    }\n",
      "    increment_log_prob(log_sum_exp(gamma[T_unsup]));\n",
      "  }\n",
      "}\n",
      "generated quantities {\n",
      "  int<lower=1,upper=K> y_star[T_unsup];\n",
      "  real log_p_y_star;\n",
      "  { \n",
      "    // Viterbi algorithm\n",
      "    int back_ptr[T_unsup,K];\n",
      "    real best_logp[T_unsup,K];\n",
      "    real best_total_logp;\n",
      "    for (k in 1:K)\n",
      "      best_logp[1,K] <- log(phi[k,u[1]]);\n",
      "    for (t in 2:T_unsup) {\n",
      "      for (k in 1:K) {\n",
      "        best_logp[t,k] <- negative_infinity();\n",
      "        for (j in 1:K) {\n",
      "          real logp;\n",
      "          logp <- best_logp[t-1,j] + log(theta[j,k]) + log(phi[k,u[t]]);\n",
      "          if (logp > best_logp[t,k]) {\n",
      "            back_ptr[t,k] <- j;\n",
      "            best_logp[t,k] <- logp;\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    log_p_y_star <- max(best_logp[T_unsup]);\n",
      "    for (k in 1:K)\n",
      "      if (best_logp[T_unsup,k] == log_p_y_star)\n",
      "        y_star[T_unsup] <- k;\n",
      "    for (t in 1:(T_unsup - 1))\n",
      "      y_star[T_unsup - t] <- back_ptr[T_unsup - t + 1, \n",
      "                                      y_star[T_unsup - t + 1]];\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "import pystan\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/stan-dev/example-models/master/misc/hmm/hmm-semisup.stan\"\n",
    "stan_model = urllib.request.urlopen(url).read().decode(\"utf-8\")\n",
    "print(stan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_14c781acf8dbbaa6f89d694cd310dd75 NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 903 ms, sys: 40.6 ms, total: 944 ms\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = pystan.StanModel(model_code=stan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K': 3,\n",
       " 'V': 10,\n",
       " 'T': 100,\n",
       " 'T_unsup': 500,\n",
       " 'alpha': DeviceArray{float32[3]},\n",
       " 'beta': DeviceArray{float32[10]},\n",
       " 'w': DeviceArray{int32[100]},\n",
       " 'z': DeviceArray{int32[100]},\n",
       " 'u': DeviceArray{int32[500]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"K\": num_categories, \"V\": num_words, \"T\": num_supervised_data, \"T_unsup\": num_unsupervised_data,\n",
    "        \"alpha\": transition_prior, \"beta\": emission_prior,\n",
    "        \"w\": supervised_words + 1, \"z\": supervised_categories + 1, \"u\": unsupervised_words + 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:4 of 100 iterations ended with a divergence (4 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 s, sys: 68.7 ms, total: 31.7 s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit = model.sampling(data, chains=1, iter=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
